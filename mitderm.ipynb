{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usted es el encargado de analítica de una empresa de telefonía celular y tiene que proporcionar soluciones para hacer frente a las problemáticas de un sector que ha llegado a saturación del mercado. Tanto su empresa como sus competidores directos tienen que disputarse por una base de clientes limitada, de tal forma que usted tiene que responder a un objetivo estratégico definido por la dirección así:\n",
    "\n",
    "“Mantener y fidelizar a nuestros clientes por medio de un servicio de calidad que se adapte a sus necesidades particulares.”\n",
    "\n",
    "Su compañía dispone de una base de datos histórica de personas que hace un año eran clientes propios. Algunos de esos clientes siguen siéndolo hoy en día, otros ya no lo son. Se han identificado dos proyectos de analítica de datos que permitirán alcanzar tal objetivo, que tendrá que desarrollar en las dos partes siguientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diccionario de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ESTADO: Describe si el usuario sigue con la compañía (VINCULADO) o no (RETIRADO)\n",
    "- INGRESOS: Promedio de ingresos del cliente en pesos\n",
    "- CASA: Precio de la casa en la que vive el cliente en pesos\n",
    "- PRECIO_DISPOSITIVO: Precio del celular del cliente en pesos\n",
    "- MESES: Antigüedad del usuario en meses\n",
    "- DURACION: Promedio de duración de las llamadas hechas por el cliente en minutos\n",
    "- SOBRECARGO: Promedio de minutos que se sobrepasa el usuario en un mes\n",
    "- SALDO_RESTANTE: Promedio de minutos de su plan que le quedan al usuario sin utilizar cada mes\n",
    "- SATISFACCION: nivel de satisfacción del usuario de 0 a 10 (muy satisfecho), obtenido a partir de una encuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import pandas as pd #tratamiento de datos\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold #protocolo de evaluación\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cargamos el archivo csv\n",
    "data=pd.read_csv(\"PF-02-DatosTelco.csv\", delimiter=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ESTADO.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificamos si existen valores atípicos en cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(241)\n",
    "plt.boxplot(data[\"INGRESOS\"])\n",
    "plt.subplot(242)\n",
    "plt.boxplot(data[\"CASA\"])\n",
    "plt.subplot(243)\n",
    "plt.boxplot(data[\"PRECIO_DISPOSITIVO\"])\n",
    "plt.subplot(244)\n",
    "plt.boxplot(data[\"MESES\"])\n",
    "plt.subplot(245)\n",
    "plt.boxplot(data[\"DURACION\"])\n",
    "plt.subplot(246)\n",
    "plt.boxplot(data[\"SOBRECARGO\"])\n",
    "plt.subplot(247)\n",
    "plt.boxplot(data[\"SALDO_RESTANTE\"])\n",
    "plt.subplot(248)\n",
    "plt.boxplot(data[\"SATISFACCION\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificamos si el dataset está balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"ESTADO\",data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ¿Encuentra alguna anomalía en los datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si, existen anomalías en los datos. Con base al análisis exploratorio previamente realizado, podemos observar que las columnas CASA, PRECIO_DISPOSITIVO Y MESES tienen registros atípicos los cuales se pueden observar en los diagramas de cajas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los datos de todas las columnas a excepción de la columna ESTADO\n",
    "independientes = data.iloc[:,1:]\n",
    "# Obtenemos los promedios de todas las columnas del dataframe independientes\n",
    "promedios = independientes.mean(axis = 0)\n",
    "# Obtenemos las desviaciones de todas las columnas del dataframe independientes\n",
    "desviaciones = independientes.std(axis = 0)\n",
    "# Obtenemos los encabezados de las columnas del dataframe independientes\n",
    "columnas = independientes.columns\n",
    "\n",
    "for i,j,z in zip(columnas,promedios,desviaciones):\n",
    "    data = data[np.abs(data[i]-j) <= 4*z]\n",
    "    \n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(241)\n",
    "plt.boxplot(data[\"INGRESOS\"])\n",
    "plt.subplot(242)\n",
    "plt.boxplot(data[\"CASA\"])\n",
    "plt.subplot(243)\n",
    "plt.boxplot(data[\"PRECIO_DISPOSITIVO\"])\n",
    "plt.subplot(244)\n",
    "plt.boxplot(data[\"MESES\"])\n",
    "plt.subplot(245)\n",
    "plt.boxplot(data[\"DURACION\"])\n",
    "plt.subplot(246)\n",
    "plt.boxplot(data[\"SOBRECARGO\"])\n",
    "plt.subplot(247)\n",
    "plt.boxplot(data[\"SALDO_RESTANTE\"])\n",
    "plt.subplot(248)\n",
    "plt.boxplot(data[\"SATISFACCION\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analice la correlación entre las variables y explique lo que puede implicar desde el punto de vista de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en la matriz de correlación, las variables INGRESOS y SALDO_RESTANTE están fuertemente\n",
    "correlacionas (de forma positiva) al igual que las variables SOBRECARGO y SATISFACCION (también de forma positiva). Para verlo gráficamente hagamos un diagrama de dispersión para cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama de dispersión INGRESO Y SALDO_RESTANTE\n",
    "x = data.INGRESOS\n",
    "y = data.SALDO_RESTANTE\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, label=\"INGRESO VS SALDO_RESTANTE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Diagrama de dispersión INGRESO Y SALDO_RESTANTE\n",
    "x = data.SOBRECARGO\n",
    "y = data.SATISFACCION\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, label=\"SOBRECARGO VS SATISFACCION\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que significa desde el punto de vista de PCA es..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Debe entrenar 3 tipos de modelos predictivos de diferentes familias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Defina el protocolo de evaluación que va a utilizar para calibrar los modelos y estimar la calidad del modelo final\n",
    "El protocolo de evaluación que vamos a usar para calibrar los modelos y estimar la calidad del modelo final será K Fold Cross Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Establezca las métricas que va a utilizar, justificando su escogencia \n",
    "Las métricas de evaluación que usaremos son: el kappa el accuracy  \n",
    "Elegimos estás metricas debido a la naturaleza del problema. El problema al que nos enfrentamos es un problema de clasificación con datos etiquetados (VINCULADO o RETIRADO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Establezca las métricas que va a utilizar, justificando su escogencia \n",
    "Calibre 3 tipos de modelos diferentes: K-NN, árbol de decisión y algún otro que propongan, utilizando las métricas y protocolo definido. <br>\n",
    "El modelo tercer modelo que usaremos es Naïve Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Refencia (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='ESTADO', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(index=data.ESTADO,columns=\"count\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(round(11665/(11665+11497) * 100, 2)) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del countplot anterior, podemos observar que nuestro dataset se encuentra balanceado.\n",
    "Nuestro Baseline es: al cabo de un año, cualquier nuevo cliente se va retirar con un accuracy de **50.36 %**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "\n",
    "Analice los clientes que se han ido, creando un modelo de segmentación de los clientes que desertan la compañía, teniendo en cuenta sus datos socio-demográficos y comportamientos de consumo del servicio de telefonía. Interpretar el perfil de clientes asignado a cada segmento, caracterizándolos de tal manera que le permita sugerir 3 a 5 campañas de fidelización.\n",
    "\n",
    "1. Definición del número de campañas a realizar (0.6)\n",
    "\n",
    "2. Extraiga los componentes principales, analice sus niveles de varianza explicada, e interprete los 3 más importantes en función de las variables originales. (0.6)\n",
    "\n",
    "3. Compare de los clusters obtenidos utilizando K-Means y Clustering jerárquico, seleccionando los resultados de uno de los dos métodos. Justifique. (0.4)\n",
    "\n",
    "4. Caracterice los clusters, etiquetando el segmento; proponga una estrategia de fidelización para cada uno de los clusters. Justifique (0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retirados=data[data.ESTADO==\"RETIRADO\"]\n",
    "retirados = retirados.drop(\"ESTADO\", axis=1)\n",
    "retirados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Componentes principales\n",
    "\n",
    "primero normalizamos los datos para poder que la escala de los variables no afecten las varianzas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(retirados)\n",
    "retirados_std = scaler.transform(retirados)\n",
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora determinamos los componentes principales de los datos y posteriormente analizamos las varianzas que las variables representan en cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "df_proyectado = pca.fit_transform(retirados_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora graficamos la varianza de cada componente para determinar los más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp=pca.explained_variance_ratio_ # varianza explicada por cada PC\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.bar(range(len(var_exp)), var_exp, alpha=0.3333, align='center', label='Varianza explicada por cada PC', color = 'g')\n",
    "plt.step(range(len(cum_var_exp)), cum_var_exp, where='mid',label='Varianza explicada acumulada')\n",
    "plt.ylabel('Porcentaje de varianza explicada')\n",
    "plt.xlabel('Componentes principales')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Los tres componentes principales más relevantes representan el \",np.sum(pca.explained_variance_ratio_[0:3])*100,\"% de la varianza de los datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retirados.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Analizando el aporte de cada variable original a cada componente tenemos que:</b>\n",
    "\n",
    "- PC1: en este componente miramos que las variables que tiene una participación positiva fuerte son <b>ingresos y saldo restante</b>. personas que no alcanzan a gastar el saldo que pagan, lo que podría ser la causa de retirarse.\n",
    "- PC2: este es caracterizado por tener participacion <b>negativa en sobrecargo y satisfacción</b>, lo que indica que este componente puede representar a los clientes a quienes los planes existentes no se ajustan a sus necesidades. este componente representa la insactisfaccion de los clientes.\n",
    "- PC3: Este componente tiene una participación <b>positiva de duración y en precio de dispositivo</b>. En esta componente podemos ver reflejados a los clientes quienes usan el servicio para realizar llamadas, es posible que sean empresarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de campañas\n",
    "\n",
    "Para definir el número de campañas usaremos el metodo del codo para determinar el mejor número de clusters en k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proyectado = pd.DataFrame(pca.fit_transform(retirados_std)[:,0:3])\n",
    "df_proyectado.columns=['PC1', 'PC2', 'PC3']\n",
    "df_proyectado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "fig = plt.figure(figsize=[10,5])\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df_proyectado[\"PC1\"], df_proyectado[\"PC2\"],df_proyectado[\"PC3\"], c='b', marker='o')\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wss_clusters(labels):\n",
    "    df_jerarquico=pd.DataFrame(labels)\n",
    "    df_jerarquico.columns=['cluster']\n",
    "    df_jerarquico[df_proyectado.columns]=df_proyectado\n",
    "    wss_average=0;\n",
    "    groups=df_jerarquico.groupby(['cluster'])\n",
    "    for g in groups:\n",
    "        wss=wss_func(g[1].iloc[:,1:])\n",
    "        wss_average+=wss\n",
    "    return wss_average/len(groups)\n",
    "\n",
    "def distance(p,q):\n",
    "    sum=0\n",
    "    for i in range(len(q)):\n",
    "        sum+=(p[i]-q[i])*(p[i]-q[i])\n",
    "    return math.sqrt(sum)\n",
    "    \n",
    "def wss_func(df):\n",
    "        averages=df.mean(axis=0)\n",
    "        wss=0\n",
    "        for val in range(len(df)):\n",
    "            row=df.iloc[val,:]\n",
    "            d=distance(row,averages)\n",
    "            wss+=d*d\n",
    "        return wss\n",
    "def centros(labels):\n",
    "    df_jerarquico=pd.DataFrame(labels)\n",
    "    df_jerarquico.columns=['cluster']\n",
    "    df_jerarquico[df_proyectado.columns]=df_proyectado\n",
    "    groups=df_jerarquico.groupby(['cluster'])\n",
    "    points=pd.DataFrame(columns=df_jerarquico.columns[1:])\n",
    "    i=0\n",
    "    for g in groups:\n",
    "        averages=g[1].iloc[:,1:].mean(axis=0)\n",
    "        points.loc[i] = averages\n",
    "        i+=1\n",
    "    return points\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=range(2,6)\n",
    "WSSs = []\n",
    "for i in n :\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(df_proyectado)\n",
    "    WSSs.append(wss_clusters(km.predict(df_proyectado)))\n",
    "prop=[]\n",
    "for i in range(len(n)-1):\n",
    "    p=(WSSs[i+1]-WSSs[i])/WSSs[i]\n",
    "    prop.append(p)\n",
    "print(prop)\n",
    "plt.plot(n, WSSs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo el metodo del codo para k desde 2 hasta 6 para poder analizar los decrecimientos de wss, el k que maximiza el decrecimiento es k=3, por ello decidimos escoger éste como el número de clusters. <b>Por ello el número de campañas a realizar son 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3, random_state=0)\n",
    "km.fit(df_proyectado)\n",
    "clusters_km=km.predict(df_proyectado)\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(131)\n",
    "plt.scatter(df_proyectado[\"PC1\"], df_proyectado[\"PC2\"], c=clusters_km, s=50, cmap='viridis')\n",
    "plt.xlabel('PC1:')\n",
    "plt.ylabel('PC2:')\n",
    "plt.subplot(132)\n",
    "plt.scatter(df_proyectado[\"PC1\"], df_proyectado[\"PC3\"], c=clusters_km, s=50, cmap='viridis')\n",
    "plt.xlabel('PC1:')\n",
    "plt.ylabel('PC3:')\n",
    "plt.subplot(133)\n",
    "plt.scatter(df_proyectado[\"PC3\"], df_proyectado[\"PC2\"], c=clusters_km, s=50, cmap='viridis')\n",
    "plt.xlabel('PC3:')\n",
    "plt.ylabel('PC2:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,5])\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df_proyectado[\"PC2\"], df_proyectado[\"PC1\"],df_proyectado[\"PC3\"], c=clusters_km, marker='o')\n",
    "\n",
    "ax.set_xlabel('PC2')\n",
    "ax.set_ylabel('PC1')\n",
    "ax.set_zlabel('PC3')\n",
    "clusters_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterin Jerarquico\n",
    "\n",
    "Para la realización del clustering jerarquico tomaremos el mismo número de clusters que en k-means, sin embargo el metodo para fusionar los clusters lo vamos a escoger dependiendo cual de ellos minimice el wss de los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=['ward','complete','average']\n",
    "fig = plt.figure(figsize=[20,5])\n",
    "c=0\n",
    "wss_list=[]\n",
    "for link in links:\n",
    "    c+=1\n",
    "    clustering = AgglomerativeClustering(linkage=link, n_clusters=3)\n",
    "    clustering.fit(df_proyectado)\n",
    "    ax = fig.add_subplot(1,3,c, projection='3d')\n",
    "    wss_list.append(wss_clusters(clustering.labels_))\n",
    "    ax.scatter(df_proyectado[\"PC2\"], df_proyectado[\"PC1\"],df_proyectado[\"PC3\"], c=clustering.labels_, marker='o')   \n",
    "    ax.set_xlabel('PC2')\n",
    "    ax.set_ylabel('PC1')\n",
    "    ax.set_zlabel('PC3')\n",
    "    ax.set_title(\"Metodo de fusion: \"+link)\n",
    "wss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pd.DataFrame(km.cluster_centers_)\n",
    "o_centers=centros(km.predict(df_proyectado))\n",
    "print(centers)\n",
    "print(o_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo usando clusterin jerarquico se selecciona un núnero de clusters igual a 3 y el método de fusion ward, debido que es el que tiene un menor wss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de clusters\n",
    "\n",
    "Para decidir cuál de los dos modelos es el mejor usaremos el criterio del que tenga el wss más bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerarquico=AgglomerativeClustering(linkage='ward', n_clusters=3)\n",
    "jerarquico.fit(df_proyectado)\n",
    "pred_jer=jerarquico.labels_\n",
    "pred_km=km.predict(df_proyectado)\n",
    "km = KMeans(n_clusters=3, random_state=0)\n",
    "km.fit(df_proyectado)\n",
    "print(\"El wss para el modelo de k-means es de:\",wss_clusters(pred_km))\n",
    "print(\"El wss para el modelo de clustering jerarquico es de:\",wss_clusters(pred_jer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=metrics.accuracy_score(pred_jer,pred_km)*100\n",
    "print(\"Podemos observar que un:\",acc,\"% de los datos fueron asignados a los mismos clusters en ambos modelos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta la suma de errores al cuadrado de los puntos al centro de su clusters <b>escogemos el modelo de k-means</b>, debido a que éste es el menor, aunque los clusters de ambos modelos quedaron muy parecidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caracterización\n",
    "\n",
    "Caracterizamos los clusters para darle la semantica necesaria deacuerdo con los componentes principales, con el fin de dirigir campañas de fidelización efectivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters=pd.DataFrame(pred_km)\n",
    "clusters.columns=['cluster']\n",
    "clusters[df_proyectado.columns]=df_proyectado\n",
    "centers = pd.DataFrame(km.cluster_centers_)\n",
    "print(clusters.head())\n",
    "print(centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_cluster(c):\n",
    "    cluster=clusters[clusters.cluster==c]\n",
    "    plt.figure(figsize=[15,5])\n",
    "    plt.subplot(131)\n",
    "    plt.scatter(cluster[\"PC1\"], cluster[\"PC2\"], c='r', s=50, cmap='viridis')\n",
    "    plt.scatter(centers.iloc[c,0],centers.iloc[c,1], c='b', s=50, cmap='viridis')\n",
    "    plt.xlabel('PC1:')\n",
    "    plt.ylabel('PC2:')\n",
    "    plt.subplot(132)\n",
    "    plt.scatter(cluster[\"PC1\"], cluster[\"PC3\"], c='r', s=50, cmap='viridis')\n",
    "    plt.scatter(centers.iloc[c,0],centers.iloc[c,2], c='b', s=50, cmap='viridis')\n",
    "    plt.xlabel('PC1:')\n",
    "    plt.ylabel('PC3:')\n",
    "    plt.subplot(133)\n",
    "    plt.scatter(cluster[\"PC3\"], cluster[\"PC2\"], c='r', s=50, cmap='viridis')\n",
    "    plt.scatter(centers.iloc[c,2],centers.iloc[c,1], c='b', s=50, cmap='viridis')\n",
    "    plt.xlabel('PC3:')\n",
    "    plt.ylabel('PC2:')\n",
    "    cluster1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_cluster(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cluster miramos que los clientes tienden a estar más inclinados a estar en el lado negativo del componente1 y neutrales encuanto a los otros dos. Como el componente 1 tiene ingresos y saldo restantes como las variables más fuertes positivamente, estos clientes son aquellos que tienen bajos ingresos y los minutos no le son suficientes cada mes. Por ello se podria pensar en un nuevo plan que contanga más minutos pero que se eleven los precios en las mismas proporciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_cluster(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este grupo de clientes se caracteriza por estar en el lado positivo del componente 1, lo que quiere decir que sus ingresos tienden a ser atos y su saldo restante es positivo. Para ellos se puede proponer acumular los minutos para el siguiente mes y al momento de acumular los minutos del plan ese mes no sea cobrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_cluster(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este grupo encontramos que los datos estan ubicados en el lado positivo del componente 2, como éste tiene fuerza negativa sobre las variables sobrecargo y satisfacción, estos clientes tienen niveles de sobrecargo y de satisfacción bajos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
